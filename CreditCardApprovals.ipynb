{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f2d84f-efff-4c77-9281-3c9ad55ae438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      690 non-null    object \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "               2           7          10             14\n",
      "count  690.000000  690.000000  690.00000     690.000000\n",
      "mean     4.758725    2.223406    2.40000    1017.385507\n",
      "std      4.978163    3.346513    4.86294    5210.102598\n",
      "min      0.000000    0.000000    0.00000       0.000000\n",
      "25%      1.000000    0.165000    0.00000       0.000000\n",
      "50%      2.750000    1.000000    0.00000       5.000000\n",
      "75%      7.207500    2.625000    3.00000     395.500000\n",
      "max     28.000000   28.500000   67.00000  100000.000000\n",
      "[[213   0]\n",
      " [  0 270]]\n",
      "Best: 0.838488 using {'max_iter': 100, 'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"~/Downloads/crx.data\", header=None) \n",
    "cc_apps.head()\n",
    "\n",
    "print(cc_apps.info())\n",
    "print(cc_apps.describe())\n",
    "\n",
    "# Replace the '?'s with NaN in dataset\n",
    "cc_apps_nans_replaced = cc_apps.replace(\"?\", np.NaN)\n",
    "\n",
    "# Create a copy of the NaN replacement DataFrame\n",
    "cc_apps_imputed = cc_apps_nans_replaced.copy()\n",
    "\n",
    "#replace NA values with the mean for numeric and most common for categorical\n",
    "for col in cc_apps_imputed.columns:\n",
    "    # Check if the column is of object type\n",
    "    if cc_apps_imputed[col].dtypes == \"object\":\n",
    "        # Impute with the most frequent value\n",
    "        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(\n",
    "            cc_apps_imputed[col].value_counts().index[0]\n",
    "        )\n",
    "    else:\n",
    "        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].mean())\n",
    "\n",
    "\n",
    "# Dummify the categorical features\n",
    "cc_apps_encoded = pd.get_dummies(cc_apps_imputed, drop_first=True)\n",
    "\n",
    "# Extract the last column as your target variable\n",
    "x = cc_apps_encoded.iloc[:, :-1].values\n",
    "y = cc_apps_encoded.iloc[:, [-1]].values\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(x_train_scaled, y_train.ravel())\n",
    "\n",
    "y_train_pred = logreg.predict(x_train_scaled)\n",
    "\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "#define grid \n",
    "tol = [.01, .001, .0001]\n",
    "max_iter = [100,150,200]\n",
    "\n",
    "param_grid = dict(tol = tol, max_iter=max_iter)\n",
    "\n",
    "grid_model = GridSearchCV(estimator = logreg, param_grid=param_grid, cv = 5)\n",
    "\n",
    "grid_model_result = grid_model.fit(x_train_scaled, y_train.ravel())\n",
    "\n",
    "best_train_score, best_train_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_train_score, best_train_params))\n",
    "\n",
    "best_model = grid_model_result.best_estimator_\n",
    "best_score = best_model.score(x_test_scaled, y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7252cf9-95b4-45e6-a12a-e7584a152ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
